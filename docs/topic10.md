---
tags:
  - SELU
courseNumber: CMPS 431
year: "2025"
courseTopic: Memory
topicDate: 2025-07-15
---
# Memory
___

>[!Links]
>1. [[cmps_431|This Course]]
>2. [[2025_summer| This Semester]]
>3. [[00_Southeastern|Southeastern Main]]

## Memory management overview

Operating systems manage memory to bridge the speed gap between fast CPUs and slower, bulkier main memory. This involves various strategies to map virtual memory to physical hardware and keep active processes in faster memory modules like caches.

### Key concepts

* **Virtual memory:** Allows execution of processes not entirely in memory, making programs larger than physical memory. It abstracts main memory into a large, uniform storage array, separating logical (programmer's view) from physical memory.
* **Locality of reference:** Principle stating that memory locations accessed after the current one are likely to be physically nearby. This justifies using small segments of memory (e.g., in cache) at a time, as the needed data is often within that segment.
* **Memory hierarchy:** Uses various levels of hardware (e.g., fast/expensive cache, slower/cheaper main memory) to optimize access speed.
* **Memory management unit (MMU):** Hardware device that performs run-time mapping from virtual to physical addresses.

## Memory issues

### Separation of process spaces

* Protects the operating system from user processes and user processes from each other.
* Each process's memory space is defined by a **base register** (smallest legal physical address) and a **limit register** (size of the range).
* CPU hardware compares every address generated in user mode with these registers; illegal access traps to the OS, treated as a fatal error.

### Address binding

Addresses can be represented differently at various program phases.
* **Compile time:** Absolute code generated if process memory location is known.
* **Load time:** Relocatable code generated if location is unknown at compile time; binding delayed until load.
* **Execution time (run time):** Binding delayed until run time if the process can move during its execution. Most OS use this, requiring special hardware (MMU).

### Logical vs. physical address space

* **Logical address (virtual address):** Address generated by the CPU (programmer's view).
* **Physical address:** Address seen by the memory unit.
* At execution-time binding, logical and physical address spaces differ.

### Dynamic loading

* Routines are loaded only when called, improving memory utilization.
* Routines are kept on disk in relocatable format.
* When a routine is needed, a relocatable linking loader loads it into memory and updates address tables.

### Contiguous memory allocation

* Assigns processes to variably sized partitions (holes) in memory.
* OS tracks available memory parts (holes).
* When a process needs memory, the system searches for a large enough hole.
* **Strategies for selecting a hole:**
    * **First fit:** Allocates the first hole large enough (faster).
    * **Best fit:** Allocates the smallest hole large enough (produces smallest leftover hole).
    * **Worst fit:** Allocates the largest hole (produces largest leftover hole, potentially more useful).
* Simulations show First Fit and Best Fit are better than Worst Fit for time and storage utilization.

### Fragmentation

* **External fragmentation:** Free memory is broken into small, non-contiguous pieces, even if total space is sufficient. (Common with First Fit and Best Fit).
    * **50-percent rule:** Approximately one-third of memory can be unusable due to fragmentation.
    * **Compaction:** Shuffles memory contents to consolidate free memory into one large block.
* **Internal fragmentation:** Unused memory within an allocated partition, occurring when allocated memory is slightly larger than requested (e.g., in paging).

## Paging

* Breaks physical memory into fixed-sized **frames** and logical memory into same-sized **pages**.
* Pages are loaded into any available frames.
* Separates logical and physical address spaces, allowing logical address space to be larger than physical memory.

### Address translation

* CPU generates a logical address, divided into a **page number (p)** and an **offset (d)**.
* Page number `p` is an index into a per-process **page table**.
* Page table entry contains the **frame number (f)**.
* Physical address is `f` + `d`.

### Frame table

* System-wide data structure tracking physical memory allocation (which frames are free, allocated, to which process/page).

### Hardware support for paging

* Page table often kept in main memory; **page-table base register (PTBR)** points to it, reducing context-switch time.
* **Translation look-aside buffer (TLB):** A special, small, fast-lookup hardware cache (associative memory) used to speed up address translation by caching page number to frame number mappings.
    * **Hit ratio:** Percentage of times a page number is found in the TLB.
    * **Effective access time:** Weighted sum of access times based on hit ratio (e.g., 0.80 * (TLB + Memory) + 0.20 * (TLB + 2 * Memory)).
    * Some TLBs allow "wired down" entries that cannot be removed.

### Paging protection

* **Protection bits:** Associated with each frame in the page table (e.g., read-write or read-only).
* **Valid-invalid bit:** In page table entry; "valid" means page is in logical address space and in memory; "invalid" means page is not valid or is in secondary storage.
* **Page-table length register (PTLR):** Hardware register indicating page table size, used to verify addresses are within valid range.

### Shared pages

* Allows multiple processes to share common code (e.g., reentrant libraries).
* Only one copy of shared code is kept in physical memory; page tables for each user process map to it.
* Shared code must be reentrant and read-only (enforced by OS).

## Structure of the page table

### Hierarchical paging (forward-mapped)

* Divides large page tables into smaller pieces.
* A two-level algorithm where the page table itself is paged.
* Logical address is divided into `p1` (index into outer page table) and `p2` (displacement within inner page table).

### Hashed page tables

* Used for address spaces larger than 32 bits.
* Each hash table entry is a linked list containing: virtual page number, mapped page frame value, and a pointer to the next element.

### Inverted page tables

* Indexes physical memory segments (frames) and records owner (PID) and logical identifier.
* Maps from physical space to logical space.
* Table index corresponds to the physical frame index.

## Swapping

* Temporarily moves a process (or part) out of memory to a backing store and back for execution.
* Increases degree of multiprogramming by allowing total physical address space of processes to exceed real physical memory.
* **Standard swapping:** Moves entire processes.
* **Swapping with paging:** Moves individual pages (e.g., Linux, Windows).
    * "Page out" and "page in" refer to moving pages.

## Virtual memory specifics

### Demand paging

* Pages are loaded into memory only when demanded during execution.
* Uses a **valid-invalid bit** in the page table:
    * "Valid": Page is legal and in memory.
    * "Invalid": Page is not valid or is in secondary storage.
* Access to an "invalid" page causes a **page fault**, trapping to the OS to bring the page into memory.
* Hardware support is the same as for paging and swapping.

### Copy-on-write

* Shared pages are marked as copy-on-write.
* If a process writes to a shared page, a copy of that page is created for that process.

### Page replacement

* When a requested page is not in main memory and no free frame is available, a **page-replacement algorithm** selects a **victim frame** to be freed.
* **Page-fault service routine steps:**
    1. Find desired page on secondary storage.
    2. Find a free frame (or select a victim using replacement algorithm).
    3. Write victim frame to secondary storage (if modified); update tables.
    4. Read desired page into freed frame; update tables.
    5. Continue process from page fault.
* **Modify bit (dirty bit):** Hardware bit for each page/frame, set if the page has been written to. If set, the page must be saved to storage before replacement; otherwise, it doesn't need to be written back.
* **Algorithms:**
    * **FIFO (first-in, first-out):** Replaces the oldest page in memory.
        * Uses a FIFO queue.
        * Can suffer from **Belady's anomaly**: increasing frames does not always improve performance.
    * **Optimal page replacement:** Replaces the page that will not be used for the longest time.
        * Theoretical, used as a benchmark.
    * **LRU (least recently used):** Replaces the page that has not been used for the longest time.
        * Requires hardware support (e.g., a priority queue or reference bits).
        * **Reference bit(s):** A bit for each page, set to 1 when referenced.
        * **Additional-reference-bits algorithm:** Uses an 8-bit byte for each page, shifting the reference bit into the high-order bit at regular intervals to record usage history. The page with the lowest resulting integer value is the LRU.
    * **Second-chance algorithm (clock algorithm):**
        * Basic FIFO with a modification.
        * When a page is selected, its reference bit is checked:
            * If 0, replace it.
            * If 1, give it a "second chance" (clear its reference bit, reset arrival time) and move to the next FIFO page.
        * Implemented as a circular queue with a pointer.

### Allocation of frames

* **Equal allocation:** Divides `m` frames equally among `n` processes (ignoring OS needs).
    * Example: 93 frames, 5 processes $\rightarrow$ 18 frames each.
* **Proportional allocation:** Allocates frames in proportion to a process's virtual memory size.
    * If $s_i$ is the size of process $p_i$'s virtual memory and $S = \sum S_i$ is the total size, then process $p_i$ gets approximately $a_i = (s_i/S) \times m$ frames.

### Thrashing

* Occurs when a process does not have enough frames to support its working set, leading to frequent page faults.
* The process spends more time paging (swapping pages in and out) than executing.
* **Prevention (page-fault frequency - PFF method):**
    * High page-fault rate indicates a need for more frames.
    * Low page-fault rate indicates potentially too many frames.
    * Establish upper and lower bounds on the desired page-fault rate to adjust frame allocation.